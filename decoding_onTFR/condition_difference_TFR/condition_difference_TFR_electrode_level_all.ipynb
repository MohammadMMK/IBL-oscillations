{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# level of analysis : single channel \n",
    "### in this notebook I compute TF difference between 3 conditions and the significance clusters based on permutation cluster test. I do analysis for all channels (clean) for all subject regardless fo the decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_test\n",
    "import h5py\n",
    "import submitit\n",
    "\n",
    "base_eid_path = '/mnt/data/AdaptiveControl/IBLrawdata/eid_data'\n",
    "base_TF_path = '/mnt/data/AdaptiveControl/IBLrawdata/TF_data'\n",
    "path_summary_data = '/crnldata/cophy/TeamProjects/mohammad/ibl-oscillations/_analyses/_IBLworkflows/preprocessing/clean_data_with_significant_channels.csv'\n",
    "summary_data = pd.read_csv(path_summary_data)\n",
    "\n",
    "\n",
    "def load_tfr(pid, ch_name, version ):\n",
    "    \"\"\"\n",
    "    Load time-frequency representation (TFR) data using MNE.\n",
    "\n",
    "    Parameters:\n",
    "    pid (str): Participant ID.\n",
    "    ch_name (str): Channel name.\n",
    "\n",
    "    Returns:\n",
    "    epochTFR (mne.time_frequency.EpochsTFR or None): The loaded TFR data. Returns None if the file is not found.\n",
    "    \"\"\"\n",
    "    tfr_path = os.path.join(base_TF_path, pid, f'powerLF_{version}_{ch_name}.h5')\n",
    "    if os.path.isfile(tfr_path):\n",
    "        epochTFR = mne.time_frequency.read_tfrs(tfr_path)\n",
    "        return epochTFR\n",
    "    else:\n",
    "        print(f'TFR file not found for {pid} - {ch_name}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_diff_average_tfr(epochTFR, condition1_trial, condition2_trial):\n",
    "    \"\"\"\n",
    "    Compute the difference in average TFR between two conditions.\n",
    "\n",
    "    Parameters:\n",
    "    epochTFR (mne.time_frequency.EpochsTFR): The TFR data.\n",
    "    condition1_trial (list of int): Indices of trials for condition 1.\n",
    "    condition2_trial (list of int): Indices of trials for condition 2.\n",
    "\n",
    "    Returns:\n",
    "    diff_data (numpy.ndarray): The difference in average TFR between the two conditions.\n",
    "    c1_data (numpy.ndarray): The log-transformed TFR data for condition 1.\n",
    "    c2_data (numpy.ndarray): The log-transformed TFR data for condition 2.\n",
    "    \"\"\"\n",
    "    c1_data = np.log10(epochTFR.data[condition1_trial].squeeze())\n",
    "    c2_data = np.log10(epochTFR.data[condition2_trial].squeeze())\n",
    "    c1_data_av = np.mean(c1_data, axis=0)\n",
    "    c2_data_av = np.mean(c2_data, axis=0)\n",
    "    diff_data = c1_data_av - c2_data_av\n",
    "    return diff_data, c1_data, c2_data\n",
    "\n",
    "\n",
    "def diff_TF_permute(row, n_permutations=500, threshold=None, version = 'csd'):\n",
    "    \"\"\"\n",
    "    Process a row of summary data to compute the difference in TFR between conditions and perform permutation tests.\n",
    "\n",
    "    Parameters:\n",
    "    row (pandas.Series): A row of the summary data.\n",
    "    n_permutations (int, optional): The number of permutations to perform in the permutation test. Default is 500.\n",
    "    threshold (float, optional): The threshold for the cluster test. Default is None.\n",
    "    version (str, optional): The version of the TFR data to load. Default is 'raw'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    eid = row['eid']\n",
    "    pid = row['pid']\n",
    "    base_TF_path = '/mnt/data/AdaptiveControl/IBLrawdata/TF_data'\n",
    "    power_files = [f for f in os.listdir(os.path.join(base_TF_path, pid)) if f.startswith(f'powerLF_{version}_')]\n",
    "\n",
    "    path_epoch_quality = f'/mnt/data/AdaptiveControl/IBLrawdata/TF_data/{pid}/epoch_quality_{version}.csv'\n",
    "\n",
    "    quality_data = pd.read_csv(path_epoch_quality)\n",
    "\n",
    "    bad_trials = quality_data[(quality_data['skewness'] > 1.5) | (quality_data['max_power'] > 500) ]['epoch'].values\n",
    "    bad_trials = list(set(bad_trials))\n",
    "    conditions = ['Stim_NoStim', 'Right_Left', 'BiasRight_BiasLeft']\n",
    "    for condition in conditions:\n",
    "\n",
    "        for channel_power in power_files:\n",
    "            tfr_path = os.path.join(base_TF_path, pid, channel_power)\n",
    "            epochTFR = mne.time_frequency.read_tfrs(tfr_path)\n",
    "            if epochTFR is None:\n",
    "                continue\n",
    "            ch_name = epochTFR.ch_names[0]\n",
    "            meta = epochTFR.metadata.reset_index()\n",
    "\n",
    "            \n",
    "            if condition == 'Stim_NoStim':\n",
    "                condition1_trial = meta.index[(meta['contrastLeft'] == 1) | (meta['contrastRight'] == 1)].tolist()\n",
    "                condition2_trial = meta.index[(meta['contrastLeft'] < 0.1) | (meta['contrastRight'] < 0.1)].tolist()\n",
    "            elif condition == 'Right_Left':\n",
    "                condition1_trial = meta.index[meta['contrastRight'] == 1].tolist()\n",
    "                condition2_trial = meta.index[meta['contrastLeft'] == 1].tolist()\n",
    "            elif condition == 'BiasRight_BiasLeft':\n",
    "                condition1_trial = meta.index[meta['probabilityLeft'] == 0.2].tolist()\n",
    "                condition2_trial = meta.index[meta['probabilityLeft'] == 0.8].tolist()\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Exclude noisy trials\n",
    "            condition1_trial = [trial for trial in condition1_trial if trial not in bad_trials]\n",
    "            condition2_trial = [trial for trial in condition2_trial if trial not in bad_trials]\n",
    "            number_of_trials = len(condition1_trial), len(condition2_trial)\n",
    "            \n",
    "            diff_data, c1_data, c2_data = compute_diff_average_tfr(epochTFR, condition1_trial, condition2_trial)\n",
    "\n",
    "            print(f'Computed difference in average TFR for {pid} - {ch_name} - {condition}')\n",
    "            print(f'Running permutation test for {pid} - {ch_name} - {condition}')\n",
    "            F_obs, clusters, cluster_p_values, H0 = permutation_cluster_test([c1_data, c2_data], out_type='mask', n_permutations=n_permutations, threshold=threshold, tail=0, n_jobs=5)\n",
    "            del c1_data, c2_data\n",
    "            print(f'Permutation test completed for {pid} - {ch_name} - {condition}')\n",
    "            ch_name_save = ch_name.replace('/', '&')\n",
    "            save_path = os.path.join(base_TF_path, pid, f'TFRpermut_LF_{condition}_{ch_name_save}_{version}_all.h5')\n",
    "            with h5py.File(save_path, 'w') as hf:\n",
    "                hf.create_dataset('diff_data', data=diff_data)\n",
    "                hf.create_dataset('F_obs', data=F_obs)\n",
    "                hf.create_dataset('clusters', data=np.array([c.astype(int) for c in clusters]))\n",
    "                hf.create_dataset('cluster_p_values', data=cluster_p_values)\n",
    "                hf.create_dataset('H0', data=H0)\n",
    "                hf.create_dataset('condition', data=np.string_(condition))  \n",
    "    \n",
    "                hf.create_dataset('eid', data=eid)\n",
    "                hf.create_dataset('pid', data=pid)\n",
    "                hf.create_dataset('ch_name', data=np.string_(ch_name))\n",
    "                hf.create_dataset('n_permutations', data=n_permutations)\n",
    "                hf.create_dataset('threshold', data=threshold if threshold is not None else np.nan)\n",
    "                hf.create_dataset('number_of_trials', data=number_of_trials)\n",
    "                hf.create_dataset('version', data=np.string_(version))\n",
    "                hf.create_dataset('times', data=epochTFR.times)\n",
    "                hf.create_dataset('freqs', data=epochTFR.freqs)\n",
    "                \n",
    "            del epochTFR    \n",
    "            print(f'Saved permutation results for {pid} - {ch_name} - {condition}')\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs submitted\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "executor = submitit.AutoExecutor(folder=\"permute_logs\")\n",
    "\n",
    "# Define maxjobs to a low value to illustrate\n",
    "maxjobs = 10000\n",
    "\n",
    "# Pass parameter to the executor\n",
    "executor.update_parameters(slurm_array_parallelism=maxjobs, mem_gb=16, timeout_min=600, slurm_partition=\"CPU\", cpus_per_task=6)\n",
    "\n",
    "\n",
    "# Execute the job (note the .map_array command that different from the .submit command used above)\n",
    "jobs = executor.map_array(diff_TF_permute, [row for _, row in summary_data.iterrows()])\n",
    "\n",
    "print(\"Jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import submitit\n",
    "\n",
    "def load_h5_file(file_path):\n",
    "    \"\"\"\n",
    "    Load data from an HDF5 file and print the datasets.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the HDF5 file.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the datasets.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        for key in hf.keys():\n",
    "            if hf[key].shape == ():  # Check if the dataset is a scalar\n",
    "                value = hf[key][()]\n",
    "                if isinstance(value, bytes):  # Check if the value is a byte string\n",
    "                    value = value.decode('utf-8')\n",
    "                data[key] = value\n",
    "            else:\n",
    "                data[key] = hf[key][:]\n",
    "                if isinstance(data[key], np.ndarray) and data[key].dtype.type is np.bytes_:\n",
    "                    data[key] = data[key].astype(str)\n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_TFR_diff(pid):\n",
    "    \n",
    "    \n",
    "    base_TF_path = '/mnt/data/AdaptiveControl/IBLrawdata/TF_data'\n",
    "    version_list = ['csd']\n",
    "    conditions = ['Stim_NoStim', 'Right_Left', 'BiasRight_BiasLeft']\n",
    "        \n",
    "        \n",
    "    for condition in conditions:\n",
    "        \n",
    "        for version in version_list:\n",
    "            \n",
    "            channel_files = [f for f in os.listdir(os.path.join(base_TF_path, pid)) if f.startswith(f'TFRpermut_LF_{condition}_') and f.endswith(f'_{version}_all.h5')]\n",
    "            \n",
    "            for file in channel_files:\n",
    "                \n",
    "                file_path = os.path.join(base_TF_path, pid, file)\n",
    "                data = load_h5_file(file_path)\n",
    "\n",
    "                diff_data= data['diff_data']\n",
    "                clusters= [data['clusters'][i] for i in range(len(data['clusters']))]\n",
    "                cluster_p_values = data['cluster_p_values']\n",
    "                timearray = data['times']\n",
    "                freqarray = data['freqs']\n",
    "                condition = data['condition']\n",
    "                channel = data['ch_name']\n",
    "                \n",
    "                number_of_trials = data['number_of_trials']\n",
    "                number_of_trials_average = number_of_trials[0] + number_of_trials[1]\n",
    "                \n",
    "                \n",
    "                # Create a mask of significant clusters\n",
    "                significant_mask = np.zeros_like(diff_data, dtype=bool)\n",
    "                for i, cluster in enumerate(clusters):\n",
    "                    if cluster_p_values[i] < 0.05:\n",
    "                        significant_mask |= cluster.astype(bool)\n",
    "\n",
    "                        \n",
    "                # Calculate time and frequency edges\n",
    "                time_edges = np.concatenate(([timearray[0] - (timearray[1] - timearray[0]) / 2],\n",
    "                                                (timearray[:-1] + timearray[1:]) / 2,\n",
    "                                                [timearray[-1] + (timearray[-1] - timearray[-2]) / 2]))\n",
    "                freq_edges = np.concatenate(([freqarray[0] - (freqarray[1] - freqarray[0]) / 2],\n",
    "                                                (freqarray[:-1] + freqarray[1:]) / 2,\n",
    "                                                [freqarray[-1] + (freqarray[-1] - freqarray[-2]) / 2]))\n",
    "\n",
    "                # Plot the difference\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.pcolormesh(time_edges, freq_edges, diff_data, cmap='RdBu_r',\n",
    "                                vmin=-np.max(np.abs(diff_data)), vmax=np.max(np.abs(diff_data)))\n",
    "                plt.colorbar(label='Difference (log10)')\n",
    "                plt.title(f'condition={condition}  ch={channel}  version={version} n_trials={number_of_trials_average}')\n",
    "                plt.xlabel('Time (seconds)')\n",
    "                plt.ylabel('Frequency (Hz)')\n",
    "\n",
    "                # Apply shading to non-significant areas\n",
    "                non_significant_mask = ~significant_mask\n",
    "                plt.pcolormesh(time_edges, freq_edges, np.ma.masked_where(non_significant_mask == False, non_significant_mask),\n",
    "                                cmap='gray', alpha=0.6)\n",
    "                dir_save = f'/crnldata/cophy/TeamProjects/mohammad/ibl-oscillations/_analyses/_IBLworkflows/decoding/figures/{pid}'\n",
    "                os.makedirs(dir_save, exist_ok=True)\n",
    "                # plt.show()\n",
    "                channel = channel.replace('/', '&')\n",
    "                \n",
    "                plt.savefig(os.path.join(dir_save, f'{condition}_{channel}_{version}.png'))\n",
    "                plt.close()\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_TF_path = '/mnt/data/AdaptiveControl/IBLrawdata/TF_data'\n",
    "\n",
    "for pid in os.listdir(base_TF_path):\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/logs/')\n",
    "    executor.update_parameters(mem_gb=4, timeout_min=300, slurm_partition=\"CPU\", cpus_per_task=1, slurm_comment='compute_epochTFR')\n",
    "    job = executor.submit(plot_TFR_diff, pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pid in enumerate(os.listdir(base_TF_path)):\n",
    "    plot_TFR_diff(pid)\n",
    "    print(f'Plotted TFR for ({i+1}/{len(os.listdir(base_TF_path))})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crnlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
