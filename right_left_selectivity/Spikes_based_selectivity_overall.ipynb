{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## not completed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import numpy as np\n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pids with files: 46 for region VISp\n"
     ]
    }
   ],
   "source": [
    "region = 'VISp'\n",
    "path_table_info = f'/crnldata/cophy/TeamProjects/mohammad/ibl-oscillations/_analyses/extraction_module/data/eid_probe_info_{region}_{region}.csv'\n",
    "table = pd.read_csv(path_table_info)\n",
    "table['pid1'] = table['pid1'].apply(ast.literal_eval)\n",
    "pids = []\n",
    "eids = []\n",
    "for i, row in enumerate(table.iterrows()):\n",
    "    eid = row[1]['eid']\n",
    "    pid1 = row[1]['pid1']\n",
    "    for pid in pid1:\n",
    "        if os.path.isfile(f'/mnt/data/AdaptiveControl/IBLrawdata/pid_data/{pid}/lfp_{pid}_raw.fif'):\n",
    "            pids.append(pid)\n",
    "            eids.append(eid)\n",
    "print(f'Number of pids with files: {len(pids)} for region {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from compute_decodability import  Right_left_decodability_SpikesOnDepths\n",
    "import submitit \n",
    "pids_short = pids[:]\n",
    "eids_short = eids[:]\n",
    "executor = submitit.AutoExecutor(folder=os.getcwd()+'/logs/')\n",
    "executor.update_parameters(mem_gb=60, timeout_min=500, slurm_partition=\"CPU\", cpus_per_task=1)\n",
    "job = executor.submit(Right_left_decodability_SpikesOnDepths, pids, eids, average_period = [0.1, 1], output_path = 'data/decodability_results.pkl', t_bin=0.1, d_bin=20, pre_stim=0.4, post_stim=1, depth_lim=[0, 3840])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: VISp1, Mean AUC-ROC: 0.3168, max: 0.5 min Num Clusters: 88\n",
      "Layer: VISp2/3, Mean AUC-ROC: 0.2803, max: 0.5 min Num Clusters: 648\n",
      "Layer: VISp4, Mean AUC-ROC: 0.2196, max: 0.5 min Num Clusters: 615\n",
      "Layer: VISp5, Mean AUC-ROC: 0.2393, max: 0.5 min Num Clusters: 1296\n",
      "Layer: VISp6a, Mean AUC-ROC: 0.2406, max: 0.5 min Num Clusters: 993\n",
      "Layer: VISp6b, Mean AUC-ROC: 0.2176, max: 0.5 min Num Clusters: 142\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the results from the pickle file\n",
    "with open('V1_cluster_decodability.pkl', 'rb') as pickle_file:\n",
    "    results = pickle.load(pickle_file)\n",
    "\n",
    "# # select the first pid\n",
    "# pid = list(results.keys())[0]\n",
    "# # Extract unique clusters\n",
    "# unique_clusters = results[pid]['unique_clusters']\n",
    "\n",
    "# Initialize lists for layers and ROC values\n",
    "layers_list = []\n",
    "ROC_list = []\n",
    "\n",
    "\n",
    "# Extract layers and ROC values from the loaded results\n",
    "for pid, data in results.items():\n",
    "    layers_list.extend(data['layers'])  # Append layers\n",
    "    ROC_list.extend(data['ROC'])        # Append ROC values\n",
    "\n",
    "# Convert lists to pandas Series and numpy array\n",
    "layers_concat = pd.Series(layers_list)\n",
    "ROC_concat = np.array(ROC_list)\n",
    "ROC_concat = np.abs(ROC_concat - 0.5)  # Adjust ROC values\n",
    "\n",
    "# Define valid regions\n",
    "valid_regions = ['VISp1', 'VISp2/3', 'VISp4', 'VISp5', 'VISp6a', 'VISp6b']\n",
    "\n",
    "# Print mean AUC-ROC and number of clusters for each valid region\n",
    "for layer in valid_regions:\n",
    "    layer_idx = layers_concat.str.contains(layer)\n",
    "    layer_ROC = ROC_concat[layer_idx]\n",
    "    \n",
    "    if layer_ROC.size > 0:  # Ensure there are clusters for the layer\n",
    "        print(f'Layer: {layer}, Mean AUC-ROC: {layer_ROC.mean():.4f}, max: {layer_ROC.max()}  Num Clusters: {layer_ROC.size}')\n",
    "    else:\n",
    "        print(f'Layer: {layer}, No valid clusters found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: VISp1, Percent Significant: 70.45%, Mean Adjusted AUC-ROC: 0.4106, Num Significant Clusters: 62\n",
      "Layer: VISp2/3, Percent Significant: 64.20%, Mean Adjusted AUC-ROC: 0.4001, Num Significant Clusters: 416\n",
      "Layer: VISp4, Percent Significant: 47.48%, Mean Adjusted AUC-ROC: 0.3746, Num Significant Clusters: 292\n",
      "Layer: VISp5, Percent Significant: 52.62%, Mean Adjusted AUC-ROC: 0.3758, Num Significant Clusters: 682\n",
      "Layer: VISp6a, Percent Significant: 54.08%, Mean Adjusted AUC-ROC: 0.3803, Num Significant Clusters: 537\n",
      "Layer: VISp6b, Percent Significant: 50.00%, Mean Adjusted AUC-ROC: 0.3721, Num Significant Clusters: 71\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for layers and ROC values\n",
    "layers_list = []\n",
    "ROC_list = []\n",
    "\n",
    "# Extract layers and ROC values from the loaded results\n",
    "for pid, data in results.items():\n",
    "    layers_list.extend(data['layers'])  # Append layers\n",
    "    ROC_list.extend(data['ROC'])        # Append ROC values\n",
    "\n",
    "# Convert lists to pandas Series and numpy array\n",
    "layers_concat = pd.Series(layers_list)\n",
    "ROC_concat = np.array(ROC_list)\n",
    "\n",
    "# Define valid regions\n",
    "valid_regions = ['VISp1', 'VISp2/3', 'VISp4', 'VISp5', 'VISp6a', 'VISp6b']\n",
    "\n",
    "# Print significant ROC statistics for each valid region\n",
    "for layer in valid_regions:\n",
    "    layer_idx = layers_concat.str.contains(layer)\n",
    "    layer_ROC = ROC_concat[layer_idx]\n",
    "    \n",
    "    if layer_ROC.size > 0:  # Ensure there are clusters for the layer\n",
    "        # Count total number of clusters in the layer\n",
    "        total_clusters = layer_ROC.size\n",
    "        \n",
    "        # Select significant ROC values (less than 0.3 or greater than 0.7)\n",
    "        signif_ROC = layer_ROC[(layer_ROC < 0.3) | (layer_ROC > 0.7)]\n",
    "        \n",
    "        # Calculate percentage of significant clusters\n",
    "        percent_signif = (signif_ROC.size / total_clusters) * 100\n",
    "        \n",
    "        # Subtract 0.5 from significant ROC values and take the absolute value\n",
    "        adjusted_signif_ROC = np.abs(signif_ROC - 0.5)\n",
    "        \n",
    "        # Compute the mean of the adjusted significant ROC values\n",
    "        if signif_ROC.size > 0:  # Ensure there are significant clusters\n",
    "            mean_adjusted_ROC = adjusted_signif_ROC.mean()\n",
    "            print(f'Layer: {layer}, Percent Significant: {percent_signif:.2f}%, Mean Adjusted AUC-ROC: {mean_adjusted_ROC:.4f}, Num Significant Clusters: {signif_ROC.size}')\n",
    "        else:\n",
    "            print(f'Layer: {layer}, No significant clusters found.')\n",
    "    else:\n",
    "        print(f'Layer: {layer}, No valid clusters found.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
