{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find session with visual area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions with passive data: 129\n"
     ]
    }
   ],
   "source": [
    "from firing_rate import firingRates_onDepths_passiveActive\n",
    "import numpy as np\n",
    "from one.api import ONE\n",
    "import json\n",
    "\n",
    "# # Initialize ONE with the IBL public server\n",
    "# one = ONE(base_url='https://openalyx.internationalbrainlab.org')\n",
    "\n",
    "# # Retrieve all probe insertions that include any of the specified visual areas\n",
    "# visual_areas = ['VISp', 'VISpm', 'VISam', 'VISa', 'VISrl', 'VISal', 'VISli', 'VISl']\n",
    "# insertions = []\n",
    "# for area in visual_areas:\n",
    "#     insertions += one.alyx.rest('insertions', 'list', task_protocol='ephys', performance_gte=70, \n",
    "#                                 dataset_qc_gte='PASS', atlas_acronym=area)\n",
    "\n",
    "# # Remove duplicates if any\n",
    "# insertions = {insertion['id']: insertion for insertion in insertions}.values()\n",
    "\n",
    "# pid_eid_pairs = [(insertion['id'], insertion['session']) for insertion in insertions]\n",
    "# print(f\"Total number of probe insertions: {len(pid_eid_pairs)}\")\n",
    "\n",
    "# eids = [eid for _, eid in pid_eid_pairs]\n",
    "# no_passive_eids = []\n",
    "# for eid in eids:\n",
    "#     datasets = one.list_datasets(eid)\n",
    "#     datasets_passive = [dataset for dataset in datasets if 'passiveGabor' in dataset]\n",
    "#     if len(datasets_passive) == 0:\n",
    "#         no_passive_eids.append(eid)\n",
    "# print(f\"Number of sessions without passive data: {len(no_passive_eids)}\")\n",
    "\n",
    "# eid_with_passive = [eid for eid in eids if eid not in no_passive_eids]\n",
    "# pid_eid_pairs = [(pid, eid) for pid, eid in pid_eid_pairs if eid in eid_with_passive]\n",
    "# print(f\"Number of sessions with passive data: {len(pid_eid_pairs)}\")\n",
    "\n",
    "# # save the pairs to a json file\n",
    "# with open('pid_eid_pairs.json', 'w') as f:\n",
    "#     json.dump(pid_eid_pairs, f)\n",
    "\n",
    "# load the pairs from the json file\n",
    "with open('pid_eid_pairs.json', 'r') as f:\n",
    "    pid_eid_pairs = json.load(f)\n",
    "print(f\"Number of sessions with passive data: {len(pid_eid_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bin=0.025 # time bins, I  tried 0.02 and wierdly the number of time points was different for active and passive data \n",
    "pre_stim=0.8 # time before stimulus onset\n",
    "post_stim= 0.4 # time after stimulus onset\n",
    "modee = 'download' # download the spikes\n",
    "min_contrast= 0 # include all trials with contrasts\n",
    "probability_left= 'all'\n",
    "min_time = -0.5\n",
    "base_path = '/mnt/data/AdaptiveControl/IBLrawdata/classification/preprocess_firingRate'\n",
    "overwrite = True\n",
    "\n",
    "from functools import partial\n",
    "# Create a partial function with fixed parameters\n",
    "firingRates_partial = partial(firingRates_onDepths_passiveActive, t_bin=t_bin,\n",
    "                              pre_stim=pre_stim,\n",
    "                              post_stim=post_stim,\n",
    "                              modee=modee,\n",
    "                              min_contrast=min_contrast,\n",
    "                              probability_left=probability_left,\n",
    "                              min_time=min_time,\n",
    "                              base_path=base_path,\n",
    "                              overwrite=overwrite)\n",
    "\n",
    "\n",
    "start = 0\n",
    "end = -1\n",
    "pid_eid_pairs_short = pid_eid_pairs[start:end]\n",
    "\n",
    "import submitit\n",
    "import time\n",
    "# prepare executor\n",
    "executor = submitit.AutoExecutor(folder=\"tuto_logs\")\n",
    "# define maxjobs to a low value to illustrate\n",
    "maxjobs= 80\n",
    "# pass parameter to the executor\n",
    "executor.update_parameters(slurm_array_parallelism=maxjobs, mem_gb=20, timeout_min=300, slurm_partition=\"CPU\", cpus_per_task=1)\n",
    "# execute the job (note the .map_array command that different from the .submit command used above)\n",
    "jobs = executor.map_array(firingRates_partial, pid_eid_pairs_short)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted 128 jobs.\n",
      "Jobs finished: 1/128\n",
      "Jobs finished: 2/128\n",
      "Jobs finished: 3/128\n",
      "Jobs finished: 4/128\n",
      "Jobs finished: 5/128\n",
      "Jobs finished: 6/128\n",
      "Jobs finished: 7/128\n",
      "Jobs finished: 8/128\n",
      "Jobs finished: 9/128\n",
      "Jobs finished: 10/128\n",
      "Jobs finished: 11/128\n",
      "Jobs finished: 12/128\n",
      "Jobs finished: 13/128\n",
      "Jobs finished: 14/128\n",
      "Jobs finished: 15/128\n",
      "Jobs finished: 16/128\n",
      "Jobs finished: 17/128\n",
      "Jobs finished: 18/128\n",
      "Jobs finished: 19/128\n",
      "Jobs finished: 20/128\n",
      "Jobs finished: 21/128\n",
      "Jobs finished: 22/128\n",
      "Jobs finished: 23/128\n",
      "Jobs finished: 24/128\n",
      "Jobs finished: 25/128\n",
      "Jobs finished: 26/128\n",
      "Jobs finished: 27/128\n",
      "Jobs finished: 28/128\n",
      "Jobs finished: 29/128\n",
      "Jobs finished: 30/128\n",
      "Jobs finished: 31/128\n",
      "Jobs finished: 32/128\n",
      "Jobs finished: 33/128\n",
      "Jobs finished: 34/128\n",
      "Jobs finished: 35/128\n",
      "Jobs finished: 36/128\n",
      "Jobs finished: 37/128\n",
      "Jobs finished: 38/128\n",
      "Jobs finished: 39/128\n",
      "Jobs finished: 40/128\n",
      "Jobs finished: 41/128\n",
      "Jobs finished: 42/128\n",
      "Jobs finished: 43/128\n",
      "Jobs finished: 44/128\n",
      "Jobs finished: 45/128\n",
      "Jobs finished: 46/128\n",
      "Jobs finished: 47/128\n",
      "Jobs finished: 48/128\n",
      "Jobs finished: 49/128\n",
      "Jobs finished: 50/128\n",
      "Jobs finished: 51/128\n",
      "Jobs finished: 52/128\n",
      "Jobs finished: 53/128\n",
      "Jobs finished: 54/128\n",
      "Jobs finished: 55/128\n",
      "Jobs finished: 56/128\n",
      "Jobs finished: 57/128\n",
      "Jobs finished: 58/128\n",
      "Jobs finished: 59/128\n",
      "Jobs finished: 60/128\n",
      "Jobs finished: 61/128\n",
      "Jobs finished: 62/128\n",
      "Jobs finished: 63/128\n",
      "Jobs finished: 64/128\n",
      "Jobs finished: 65/128\n",
      "Jobs finished: 66/128\n",
      "Jobs finished: 67/128\n",
      "Jobs finished: 68/128\n",
      "Jobs finished: 69/128\n",
      "Jobs finished: 70/128\n",
      "Jobs finished: 71/128\n",
      "Jobs finished: 72/128\n",
      "Jobs finished: 73/128\n",
      "Jobs finished: 74/128\n",
      "Jobs finished: 75/128\n",
      "Jobs finished: 76/128\n",
      "Jobs finished: 77/128\n",
      "Jobs finished: 78/128\n",
      "Jobs finished: 79/128\n",
      "Jobs finished: 80/128\n",
      "Jobs finished: 81/128\n",
      "Jobs finished: 82/128\n",
      "Jobs finished: 83/128\n",
      "Jobs finished: 84/128\n",
      "Jobs finished: 85/128\n",
      "Jobs finished: 86/128\n",
      "Jobs finished: 87/128\n",
      "Jobs finished: 88/128\n",
      "Jobs finished: 89/128\n",
      "Jobs finished: 90/128\n",
      "Jobs finished: 91/128\n",
      "Jobs finished: 92/128\n",
      "Jobs finished: 93/128\n",
      "Jobs finished: 94/128\n",
      "Jobs finished: 95/128\n",
      "Jobs finished: 96/128\n",
      "Jobs finished: 97/128\n",
      "Jobs finished: 98/128\n",
      "Jobs finished: 99/128\n",
      "Jobs finished: 100/128\n",
      "Jobs finished: 101/128\n",
      "Jobs finished: 102/128\n",
      "Jobs finished: 103/128\n",
      "Jobs finished: 104/128\n",
      "Jobs finished: 105/128\n",
      "Jobs finished: 106/128\n",
      "Jobs finished: 107/128\n",
      "Jobs finished: 108/128\n",
      "Jobs finished: 109/128\n",
      "Jobs finished: 110/128\n",
      "Jobs finished: 111/128\n",
      "Jobs finished: 112/128\n",
      "Jobs finished: 113/128\n",
      "Jobs finished: 114/128\n",
      "Jobs finished: 115/128\n",
      "Jobs finished: 116/128\n",
      "Jobs finished: 117/128\n",
      "Jobs finished: 118/128\n",
      "Jobs finished: 119/128\n",
      "Jobs finished: 120/128\n",
      "Jobs finished: 121/128\n",
      "Jobs finished: 122/128\n",
      "Jobs finished: 123/128\n",
      "Jobs finished: 124/128\n",
      "Jobs finished: 125/128\n",
      "Jobs finished: 126/128\n",
      "Jobs finished: 127/128\n",
      "Jobs finished: 128/128\n",
      "All jobs are finished.\n"
     ]
    }
   ],
   "source": [
    "# Monitor job status\n",
    "total_jobs = len(jobs)\n",
    "print(f\"Submitted {total_jobs} jobs.\")\n",
    "\n",
    "finished_jobs = 0\n",
    "completed_jobs_set = set()\n",
    "\n",
    "while finished_jobs < total_jobs:\n",
    "    for idx, job in enumerate(jobs):\n",
    "        if job.done() and idx not in completed_jobs_set:\n",
    "            finished_jobs += 1\n",
    "            completed_jobs_set.add(idx)\n",
    "            print(f\"Jobs finished: {finished_jobs}/{total_jobs}\")\n",
    "\n",
    "print(\"All jobs are finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already done jobs: 0\n",
      "Mismatch jobs: 0\n",
      "Bad turns good jobs: 127\n",
      "Unsuccess jobs: 1\n"
     ]
    }
   ],
   "source": [
    "alreadydon_jobs = []\n",
    "mismatch_jobs = []\n",
    "badturnsgood_jobs = []\n",
    "unsuccess_jobs = []\n",
    "for job in jobs:\n",
    "    try:\n",
    "        result = job.result()\n",
    "        if result == 1:\n",
    "            alreadydon_jobs.append(job)\n",
    "        elif result == 2:\n",
    "            mismatch_jobs.append(job)\n",
    "        elif result == 0:\n",
    "            badturnsgood_jobs.append(job)\n",
    "    except:\n",
    "        unsuccess_jobs.append(job)\n",
    "        continue\n",
    "print(f'Already done jobs: {len(alreadydon_jobs)}')\n",
    "print(f'Mismatch jobs: {len(mismatch_jobs)}')\n",
    "print(f'Bad turns good jobs: {len(badturnsgood_jobs)}')\n",
    "print(f'Unsuccess jobs: {len(unsuccess_jobs)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
